{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/root1/.virtualenv/demos/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "random.seed(1984)\n",
    "\n",
    "INPUT_PADDING = 50\n",
    "OUTPUT_PADDING = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "\n",
    "    def __init__(self, vocabulary_file, padding=None):\n",
    "        \"\"\"\n",
    "            Creates a vocabulary from a file\n",
    "            :param vocabulary_file: the path to the vocabulary\n",
    "        \"\"\"\n",
    "        \n",
    "        # set vocabulary file, padding and reverse vocabulary\n",
    "        \n",
    "        self.vocabulary_file = vocabulary_file\n",
    "        with open(vocabulary_file, 'r') as f:\n",
    "            self.vocabulary = json.load(f)\n",
    "\n",
    "        self.padding = padding\n",
    "        self.reverse_vocabulary = {v: k for k, v in self.vocabulary.items()}\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "            returns the size of the vocabulary\n",
    "        \"\"\"\n",
    "        return len(self.vocabulary.keys())\n",
    "\n",
    "    def string_to_int(self, text):\n",
    "        \"\"\"\n",
    "            Converts a string into it's character integer \n",
    "            representation\n",
    "            :param text: text to convert\n",
    "        \"\"\"\n",
    "        # get the characters\n",
    "        characters = list(text)\n",
    "\n",
    "        # integer representation\n",
    "        integers = []\n",
    "\n",
    "        # pick first k characters where k = self.padding\n",
    "        if self.padding and len(characters) >= self.padding:\n",
    "            # truncate if too long\n",
    "            characters = characters[:self.padding - 1]\n",
    "        \n",
    "        # append special characters\n",
    "        characters.append('<eot>')\n",
    "        \n",
    "        # append the integer equivalent\n",
    "        for c in characters:\n",
    "            if c in self.vocabulary:\n",
    "                integers.append(self.vocabulary[c])\n",
    "            else:\n",
    "                integers.append(self.vocabulary['<unk>'])\n",
    "\n",
    "\n",
    "        # pad the data if its shorter\n",
    "        if self.padding and len(integers) < self.padding:\n",
    "            integers.extend([self.vocabulary['<unk>']]\n",
    "                            * (self.padding - len(integers)))\n",
    "\n",
    "        if len(integers) != self.padding:\n",
    "            print(text)\n",
    "            raise AttributeError('Length of text was not padding.')\n",
    "        return integers\n",
    "\n",
    "    def int_to_string(self, integers):\n",
    "        \"\"\"\n",
    "            Decodes a list of integers\n",
    "            into it's string representation\n",
    "        \"\"\"\n",
    "        characters = []\n",
    "        for i in integers:\n",
    "            characters.append(self.reverse_vocabulary[i])\n",
    "\n",
    "        return characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "\n",
    "    def __init__(self, file_name, input_vocabulary, output_vocabulary):\n",
    "        \"\"\"\n",
    "            Creates an object that gets data from a file\n",
    "            :param file_name: name of the file to read from\n",
    "            :param vocabulary: the Vocabulary object to use\n",
    "            :param batch_size: the number of datapoints to return\n",
    "            :param padding: the amount of padding to apply to \n",
    "                            a short string\n",
    "        \"\"\"\n",
    "        \n",
    "        # set vocab files and data file\n",
    "        self.input_vocabulary = input_vocabulary\n",
    "        self.output_vocabulary = output_vocabulary\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "            Loads data from a file\n",
    "        \"\"\"\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        # load the data\n",
    "        with open(self.file_name, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                self.inputs.append(row[0])\n",
    "                self.targets.append(row[1])\n",
    "\n",
    "    def transform(self):\n",
    "        \"\"\"\n",
    "            Transforms the data as necessary\n",
    "        \"\"\"\n",
    "        # @TODO: use `pool.map_async` here?\n",
    "        \n",
    "        # convert string to int\n",
    "        self.inputs = np.array(list(map(self.input_vocabulary.string_to_int, self.inputs)))\n",
    "        self.targets = map(self.output_vocabulary.string_to_int, self.targets)\n",
    "        \n",
    "        #output is a seq of integers - we represent each integer as 1-hopt encoding\n",
    "        self.targets = np.array(\n",
    "            list(map(\n",
    "                lambda x: to_categorical(\n",
    "                    x,\n",
    "                    num_classes=self.output_vocabulary.size()),\n",
    "                self.targets)))\n",
    "        \n",
    "        # noit sure what exactly is this for \n",
    "        assert len(self.inputs.shape) == 2, 'Inputs could not properly be encoded'\n",
    "        assert len(self.targets.shape) == 3, 'Targets could not properly be encoded'\n",
    "\n",
    "    def generator(self, batch_size):\n",
    "        \"\"\"\n",
    "            Creates a generator that can be used in `model.fit_generator()`\n",
    "            Batches are generated randomly.\n",
    "            :param batch_size: the number of instances to include per batch\n",
    "        \"\"\"\n",
    "        instance_id = range(len(self.inputs))\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                \n",
    "                batch_ids = random.sample(instance_id, batch_size) # random chose a batch\n",
    "                yield (np.array(self.inputs[batch_ids], dtype=int), np.array(self.targets[batch_ids]))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print('EXCEPTION OMG')\n",
    "                print(e)\n",
    "                yield None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "DATA_FOLDER = os.path.join(cwd, 'data')\n",
    "input_vocab_file_path = os.path.join(DATA_FOLDER, 'human_vocab.json')\n",
    "output_vocab_file_path = os.path.join(DATA_FOLDER, 'machine_vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab = Vocabulary(input_vocab_file_path, padding=50)\n",
    "output_vocab = Vocabulary(output_vocab_file_path, padding=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv_file_path = os.path.join(DATA_FOLDER, 'training.csv')\n",
    "\n",
    "ds = Data(sample_csv_file_path, input_vocab, output_vocab)\n",
    "ds.load()\n",
    "ds.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 50)\n",
      "(500000, 12, 13)\n",
      "(3, 50)\n",
      "(3, 12, 13)\n"
     ]
    }
   ],
   "source": [
    "print(ds.inputs.shape)\n",
    "print(ds.targets.shape)\n",
    "\n",
    "g = ds.generator(32)\n",
    "\n",
    "\n",
    "print(ds.inputs[[5,10, 12]].shape)\n",
    "print(ds.targets[[5,10,12]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generator at 0x7fe096b172d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
