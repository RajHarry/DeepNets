{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/philipperemy/keras-attention-mechanism/blob/master/attention_dense.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "    # Documentation is available online on Github at the address below.\n",
    "    # From: https://github.com/philipperemy/keras-visualize-activations\n",
    "    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "    funcs = [K.function([inp] + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def get_data(n, input_dim, attention_column=1):\n",
    "    \"\"\"\n",
    "    Data generation. x is purely random except that it's first value equals the target y.\n",
    "    In practice, the network should learn that the target = x[attention_column].\n",
    "    Therefore, most of its attention should be focused on the value addressed by attention_column.\n",
    "    :param n: the number of samples to retrieve.\n",
    "    :param input_dim: the number of dimensions of each element in the series.\n",
    "    :param attention_column: the column linked to the target. Everything else is purely random.\n",
    "    :return: x: model inputs, y: model targets\n",
    "    \"\"\"\n",
    "    x = np.random.standard_normal(size=(n, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column] = y[:, 0]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_data_recurrent(n, time_steps, input_dim, attention_column=10):\n",
    "    \"\"\"\n",
    "    Data generation. x is purely random except that it's first value equals the target y.\n",
    "    In practice, the network should learn that the target = x[attention_column].\n",
    "    Therefore, most of its attention should be focused on the value addressed by attention_column.\n",
    "    :param n: the number of samples to retrieve.\n",
    "    :param time_steps: the number of time steps of your series.\n",
    "    :param input_dim: the number of dimensions of each element in the series.\n",
    "    :param attention_column: the column linked to the target. Everything else is purely random.\n",
    "    :return: x: model inputs, y: model targets\n",
    "    \"\"\"\n",
    "    x = np.random.standard_normal(size=(n, time_steps, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column, :] = np.tile(y[:], (1, input_dim))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\legacy\\layers.py:464: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Dense)           (None, 32)           1056        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_mul (Merge)           (None, 32)           0           input_7[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           2112        attention_mul[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            65          dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,233\n",
      "Trainable params: 3,233\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/40\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 0.1155 - acc: 0.9475 - val_loss: 1.7846e-04 - val_acc: 1.0000\n",
      "Epoch 2/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 7.0071e-05 - acc: 1.0000 - val_loss: 2.5375e-05 - val_acc: 1.0000\n",
      "Epoch 3/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 1.2900e-05 - acc: 1.0000 - val_loss: 6.0149e-06 - val_acc: 1.0000\n",
      "Epoch 4/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 3.2207e-06 - acc: 1.0000 - val_loss: 1.5627e-06 - val_acc: 1.0000\n",
      "Epoch 5/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 8.4256e-07 - acc: 1.0000 - val_loss: 4.0997e-07 - val_acc: 1.0000\n",
      "Epoch 6/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 2.4331e-07 - acc: 1.0000 - val_loss: 1.5559e-07 - val_acc: 1.0000\n",
      "Epoch 7/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 1.2817e-07 - acc: 1.0000 - val_loss: 1.1598e-07 - val_acc: 1.0000\n",
      "Epoch 8/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 1.1237e-07 - acc: 1.0000 - val_loss: 1.1082e-07 - val_acc: 1.0000\n",
      "Epoch 9/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.1019e-07 - acc: 1.0000 - val_loss: 1.0993e-07 - val_acc: 1.0000\n",
      "Epoch 10/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 1.0975e-07 - acc: 1.0000 - val_loss: 1.0972e-07 - val_acc: 1.0000\n",
      "Epoch 11/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0963e-07 - acc: 1.0000 - val_loss: 1.0965e-07 - val_acc: 1.0000\n",
      "Epoch 12/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0963e-07 - val_acc: 1.0000\n",
      "Epoch 13/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0958e-07 - acc: 1.0000 - val_loss: 1.0961e-07 - val_acc: 1.0000\n",
      "Epoch 14/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0957e-07 - acc: 1.0000 - val_loss: 1.0961e-07 - val_acc: 1.0000\n",
      "Epoch 15/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0957e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 16/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0957e-07 - acc: 1.0000 - val_loss: 1.0961e-07 - val_acc: 1.0000\n",
      "Epoch 17/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 18/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 19/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 20/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 21/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 22/40\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 23/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 24/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 25/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 26/40\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 27/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 28/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 29/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 30/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 31/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 32/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 33/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 34/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 35/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 36/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 37/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 38/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 39/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "----- activations -----\n",
      "(1, 32)\n",
      "attention = [0.01550892 0.01722926 0.01894277 0.02258679 0.00896666 0.5299228\n",
      " 0.01965744 0.02101863 0.01372286 0.01177535 0.01513958 0.01432017\n",
      " 0.01555399 0.00907843 0.01264607 0.0233934  0.01382033 0.01157602\n",
      " 0.00583442 0.01934581 0.01307259 0.00861341 0.01362178 0.01713734\n",
      " 0.00913493 0.01484092 0.01117685 0.02174224 0.01687778 0.01733731\n",
      " 0.02619271 0.01021241]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119c3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#from attention_utils import get_activations, get_data\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Dense, merge\n",
    "\n",
    "input_dim = 32\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # ATTENTION PART STARTS HERE\n",
    "    attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)\n",
    "    attention_mul = merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "    # ATTENTION PART FINISHES HERE\n",
    "\n",
    "    attention_mul = Dense(64)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    N = 100000\n",
    "    inputs_1, outputs = get_data(N, input_dim, attention_column=5)\n",
    "\n",
    "    m = build_model()\n",
    "    m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(m.summary())\n",
    "\n",
    "    m.fit([inputs_1], outputs, epochs=40, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    testing_inputs_1, testing_outputs = get_data(1, input_dim)\n",
    "\n",
    "    # Attention vector corresponds to the second matrix.\n",
    "    # The first one is the Inputs output.\n",
    "    attention_vector = get_activations(m, testing_inputs_1,\n",
    "                                       print_shape_only=True,\n",
    "                                       layer_name='attention_vec')[0].flatten()\n",
    "    print('attention =', attention_vector)\n",
    "\n",
    "    # plot part.\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    pd.DataFrame(attention_vector, columns=['attention (%)']).plot(kind='bar',\n",
    "                                                                   title='Attention Mechanism as '\n",
    "                                                                         'a function of input'\n",
    "                                                                         ' dimensions.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\legacy\\layers.py:464: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Dense)           (None, 32)           1056        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_mul (Merge)           (None, 32)           0           input_8[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           2112        attention_mul[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            65          dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,233\n",
      "Trainable params: 3,233\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/40\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.1138 - acc: 0.9491 - val_loss: 1.7716e-04 - val_acc: 1.0000\n",
      "Epoch 2/40\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 7.2173e-05 - acc: 1.0000 - val_loss: 2.5616e-05 - val_acc: 1.0000\n",
      "Epoch 3/40\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 1.3333e-05 - acc: 1.0000 - val_loss: 6.0370e-06 - val_acc: 1.0000\n",
      "Epoch 4/40\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 3.3074e-06 - acc: 1.0000 - val_loss: 1.5607e-06 - val_acc: 1.0000\n",
      "Epoch 5/40\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 8.6267e-07 - acc: 1.0000 - val_loss: 4.1111e-07 - val_acc: 1.0000\n",
      "Epoch 6/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 2.5047e-07 - acc: 1.0000 - val_loss: 1.5783e-07 - val_acc: 1.0000\n",
      "Epoch 7/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 1.3086e-07 - acc: 1.0000 - val_loss: 1.1695e-07 - val_acc: 1.0000\n",
      "Epoch 8/40\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.1306e-07 - acc: 1.0000 - val_loss: 1.1103e-07 - val_acc: 1.0000\n",
      "Epoch 9/40\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.1029e-07 - acc: 1.0000 - val_loss: 1.0999e-07 - val_acc: 1.0000\n",
      "Epoch 10/40\n",
      "80000/80000 [==============================] - 4s 47us/step - loss: 1.0976e-07 - acc: 1.0000 - val_loss: 1.0973e-07 - val_acc: 1.0000\n",
      "Epoch 11/40\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 1.0963e-07 - acc: 1.0000 - val_loss: 1.0965e-07 - val_acc: 1.0000\n",
      "Epoch 12/40\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.0959e-07 - acc: 1.0000 - val_loss: 1.0962e-07 - val_acc: 1.0000\n",
      "Epoch 13/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0957e-07 - acc: 1.0000 - val_loss: 1.0961e-07 - val_acc: 1.0000\n",
      "Epoch 14/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0957e-07 - acc: 1.0000 - val_loss: 1.0961e-07 - val_acc: 1.0000\n",
      "Epoch 15/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 16/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 17/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 18/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 19/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 20/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 21/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 22/40\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 23/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 24/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 25/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 26/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 27/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 28/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 29/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 30/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 31/40\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 32/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 33/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 34/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 35/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 36/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 37/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 38/40\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 39/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 1.0956e-07 - acc: 1.0000 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
      "----- activations -----\n",
      "(1, 32)\n",
      "attention = [0.01090996 0.00894436 0.02210772 0.01009254 0.00316787 0.00810134\n",
      " 0.00902837 0.00950304 0.0079906  0.0048348  0.0080725  0.00824473\n",
      " 0.00769107 0.00479035 0.01376699 0.00760162 0.00855002 0.00710635\n",
      " 0.0041031  0.0058297  0.00877823 0.7232342  0.00706335 0.00931719\n",
      " 0.00352033 0.01004332 0.00690248 0.02249232 0.00754907 0.01174922\n",
      " 0.01553642 0.00337683]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ca0588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#from attention_utils import get_activations, get_data\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Dense, merge\n",
    "\n",
    "input_dim = 32\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # ATTENTION PART STARTS HERE\n",
    "    attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)\n",
    "    attention_mul = merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "    # ATTENTION PART FINISHES HERE\n",
    "\n",
    "    attention_mul = Dense(64)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    N = 100000\n",
    "    inputs_1, outputs = get_data(N, input_dim, attention_column=21)\n",
    "\n",
    "    m = build_model()\n",
    "    m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(m.summary())\n",
    "\n",
    "    m.fit([inputs_1], outputs, epochs=40, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    testing_inputs_1, testing_outputs = get_data(1, input_dim)\n",
    "\n",
    "    # Attention vector corresponds to the second matrix.\n",
    "    # The first one is the Inputs output.\n",
    "    attention_vector = get_activations(m, testing_inputs_1,\n",
    "                                       print_shape_only=True,\n",
    "                                       layer_name='attention_vec')[0].flatten()\n",
    "    print('attention =', attention_vector)\n",
    "\n",
    "    # plot part.\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    pd.DataFrame(attention_vector, columns=['attention (%)']).plot(kind='bar',\n",
    "                                                                   title='Attention Mechanism as '\n",
    "                                                                         'a function of input'\n",
    "                                                                         ' dimensions.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
