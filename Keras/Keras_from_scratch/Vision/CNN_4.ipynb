{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pretrained convnet\n",
    "\n",
    "    - Extract features using pretrained classifier and feed them to a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1:\n",
    "    - Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2\n",
    "\n",
    "    - Extracting features using the pretrained convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'D:\\Datasets\\cats_and_dogs_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract featuresin bulk\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    #declare empty tensors\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    \n",
    "    #create a generator\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                    target_size=(150, 150),\n",
    "                                    batch_size=batch_size,\n",
    "                                    class_mode='binary')\n",
    "    \n",
    "    # iterate \n",
    "    i = 0  # i is used to index the tensors\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch) # get the features for batch\n",
    "        \n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "            \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 80000 bytes but only got 0. Skipping tag 64640\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6553600 bytes but only got 0. Skipping tag 49\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1050744 bytes but only got 4951. Skipping tag 51\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293339136 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293863424 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3368026112 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 134479872 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 295698432 bytes but only got 0. Skipping tag 10\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 296222720 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 14745600 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25624576 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 317718528 bytes but only got 4956. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 4952. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 393216 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287178752 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287703040 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 524288 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 286654464 bytes but only got 4956. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404094976 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404619264 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 425459712 bytes but only got 0. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 6833. Skipping tag 513\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 6833. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "c:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\PIL\\TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the feature sets\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3\n",
    "    - densely connected classifier that will use the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.6168 - acc: 0.6545 - val_loss: 0.4351 - val_acc: 0.8480\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4220 - acc: 0.8175 - val_loss: 0.3577 - val_acc: 0.8720\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3515 - acc: 0.8530 - val_loss: 0.3223 - val_acc: 0.8630\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3134 - acc: 0.8665 - val_loss: 0.2936 - val_acc: 0.8850\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2829 - acc: 0.8870 - val_loss: 0.2774 - val_acc: 0.8870\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2590 - acc: 0.8920 - val_loss: 0.2668 - val_acc: 0.8900\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2467 - acc: 0.8985 - val_loss: 0.2575 - val_acc: 0.8940\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2325 - acc: 0.9055 - val_loss: 0.2538 - val_acc: 0.8970\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2159 - acc: 0.9140 - val_loss: 0.2507 - val_acc: 0.8980\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2085 - acc: 0.9220 - val_loss: 0.2420 - val_acc: 0.9020\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1918 - acc: 0.9290 - val_loss: 0.2398 - val_acc: 0.9020\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1868 - acc: 0.9270 - val_loss: 0.2390 - val_acc: 0.9020\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1704 - acc: 0.9415 - val_loss: 0.2371 - val_acc: 0.9030\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1683 - acc: 0.9420 - val_loss: 0.2339 - val_acc: 0.9040\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1608 - acc: 0.9420 - val_loss: 0.2327 - val_acc: 0.9050\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1515 - acc: 0.9410 - val_loss: 0.2305 - val_acc: 0.9020\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1445 - acc: 0.9505 - val_loss: 0.2354 - val_acc: 0.9040\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1388 - acc: 0.9465 - val_loss: 0.2302 - val_acc: 0.9050\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1338 - acc: 0.9495 - val_loss: 0.2300 - val_acc: 0.9050\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1329 - acc: 0.9530 - val_loss: 0.2293 - val_acc: 0.9050\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1251 - acc: 0.9580 - val_loss: 0.2379 - val_acc: 0.9070\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1141 - acc: 0.9640 - val_loss: 0.2278 - val_acc: 0.9050\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1115 - acc: 0.9610 - val_loss: 0.2284 - val_acc: 0.9080\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1099 - acc: 0.9640 - val_loss: 0.2311 - val_acc: 0.9100\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1021 - acc: 0.9685 - val_loss: 0.2325 - val_acc: 0.9080\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1006 - acc: 0.9670 - val_loss: 0.2445 - val_acc: 0.9030\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0910 - acc: 0.9720 - val_loss: 0.2335 - val_acc: 0.9070\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0919 - acc: 0.9725 - val_loss: 0.2552 - val_acc: 0.8970\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.0869 - acc: 0.9730 - val_loss: 0.2315 - val_acc: 0.9100\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.0808 - acc: 0.9795 - val_loss: 0.2392 - val_acc: 0.9040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "loss='binary_crossentropy',\n",
    "metrics=['acc'])\n",
    "\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "epochs=30,\n",
    "batch_size=20,\n",
    "validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x35823c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeacd390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION WITH DATA AUGMENTATION\n",
    "\n",
    "    - Adding a densely connected classifier on top of the convolutional base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 \n",
    "\n",
    "    - load the pretrained model and add more layer on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150, 150, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Doubt : not quite sure why am I getting 30 and 4 in above 3 cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2:\n",
    "    - basic stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = 'D:\\Datasets\\cats_and_dogs_small'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3:\n",
    "    - Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f2327c060844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m       verbose=2)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1254\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a00439512\\appdata\\local\\continuum\\anaconda3\\envs\\demo\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)\n",
    "\n",
    "## this is painfully slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
